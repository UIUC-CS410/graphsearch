{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def definition(inputFile):\n",
    "    hashMap = {}\n",
    "    with open(inputFile) as f:\n",
    "        content = f.read().splitlines()\n",
    "\n",
    "    for i in xrange(len(content)):\n",
    "        (index, definition) = content[i].split('\\t')\n",
    "        hashMap[int(index)] = definition\n",
    "        \n",
    "    return (hashMap, list(sorted(hashMap.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(authors, aIndices) = definition('original/author.txt')\n",
    "(papers, pIndices) = definition('original/paper.txt')\n",
    "(terms, tIndices) = definition('original/term.txt')\n",
    "(venues, vIndices) = definition('original/venue.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def formMatrices(inputFile):\n",
    "    # need to create M_AP, M_PV, M_PT\n",
    "    ap_row = []\n",
    "    ap_col = []\n",
    "    pv_row = []\n",
    "    pv_col = []\n",
    "    pt_row = []\n",
    "    pt_col = []\n",
    "    \n",
    "    a2p = {}\n",
    "    p2a = {}\n",
    "    p2v = {}\n",
    "    v2p = {}\n",
    "    p2t = {}\n",
    "    t2p = {}\n",
    "    \n",
    "    with open(inputFile) as f:\n",
    "        content = f.read().splitlines()\n",
    "\n",
    "    for i in xrange(len(content)):\n",
    "        (paper, item, _) = content[i].split('\\t')\n",
    "        paper = int(paper)\n",
    "        item = int(item)\n",
    "        \n",
    "        if (item <= 13575): # this is a term => update M_PT\n",
    "            pt_row.append(pIndices.index(paper))\n",
    "            pt_col.append(tIndices.index(item))\n",
    "            \n",
    "            if paper in p2t:\n",
    "                p2t[paper].append(item)\n",
    "            else:\n",
    "                p2t[paper] = [item]\n",
    "                \n",
    "            if item in t2p:\n",
    "                t2p[item].append(paper)\n",
    "            else:\n",
    "                t2p[item] = [paper]\n",
    "                \n",
    "        elif (42145 <= item and item <= 42164): # venue => update M_PV\n",
    "            pv_row.append(pIndices.index(paper))\n",
    "            pv_col.append(vIndices.index(item))\n",
    "            \n",
    "            if paper in p2v:\n",
    "                p2v[paper].append(item)\n",
    "            else:\n",
    "                p2v[paper] = [item]\n",
    "                \n",
    "            if item in v2p:\n",
    "                v2p[item].append(paper)\n",
    "            else:\n",
    "                v2p[item] = [paper]\n",
    "            \n",
    "        else: # author => update M_AP\n",
    "            ap_row.append(aIndices.index(item))\n",
    "            ap_col.append(pIndices.index(paper))\n",
    "            \n",
    "            if paper in p2a:\n",
    "                p2a[paper].append(item)\n",
    "            else:\n",
    "                p2a[paper] = [item]\n",
    "                \n",
    "            if item in a2p:\n",
    "                a2p[item].append(paper)\n",
    "            else:\n",
    "                a2p[item] = [paper]\n",
    "\n",
    "    AP = csr_matrix((np.ones(len(ap_row)), (ap_row, ap_col)), dtype=np.float64)\n",
    "    PT = csr_matrix((np.ones(len(pt_row)), (pt_row, pt_col)), dtype=np.float64)\n",
    "    PV = csr_matrix((np.ones(len(pv_row)), (pv_row, pv_col)), dtype=np.float64)\n",
    "    \n",
    "    return (AP*np.transpose(AP),\n",
    "            AP*PT*np.transpose(PT)*np.transpose(AP),\n",
    "            AP*PV*np.transpose(PV)*np.transpose(AP),\n",
    "           a2p, p2a, p2v, v2p, p2t, t2p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(APA, APTPA, APVPA, A2P, P2A, P2V, V2P, P2T, T2P) = formMatrices('original/relation.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write2file(name, matrix):\n",
    "    with open(name + '.txt', 'w') as f:\n",
    "        (row, col) = matrix.nonzero()\n",
    "        for i in xrange(len(row)):\n",
    "            f.write(row[i].__str__() + '\\t' + col[i].__str__() + '\\t' + matrix[row[i], col[i]].__str__() + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write2file('APTPA_', APTPAhalf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write2file('APVPA_', APVPAhalf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write2file('APA_', APAhalf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "APTPArows = []\n",
    "APTPAcols = []\n",
    "APTPAvals = []\n",
    "(rows, cols) = APTPA.nonzero()\n",
    "\n",
    "for i in xrange(len(rows)):\n",
    "    if rows[i] <= cols[i]:\n",
    "        APTPArows.append(rows[i])\n",
    "        APTPAcols.append(cols[i])\n",
    "        APTPAvals.append(APTPA[rows[i], cols[i]])\n",
    "        \n",
    "APTPAhalf = csr_matrix((APTPAvals, (APTPArows, APTPAcols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "APArows = []\n",
    "APAcols = []\n",
    "APAvals = []\n",
    "(rows, cols) = APA.nonzero()\n",
    "\n",
    "for i in xrange(len(rows)):\n",
    "    if rows[i] >= cols[i]:\n",
    "        APArows.append(rows[i])\n",
    "        APAcols.append(cols[i])\n",
    "        APAvals.append(APA[rows[i], cols[i]])\n",
    "        \n",
    "APAhalf = csr_matrix((APAvals, (APArows, APAcols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "APVPArows = []\n",
    "APVPAcols = []\n",
    "APVPAvals = []\n",
    "(rows, cols) = APVPA.nonzero()\n",
    "\n",
    "for i in xrange(len(rows)):\n",
    "    if rows[i] <= cols[i]:\n",
    "        APVPArows.append(rows[i])\n",
    "        APVPAcols.append(cols[i])\n",
    "        APVPAvals.append(APVPA[rows[i], cols[i]])\n",
    "        \n",
    "APVPAhalf = csr_matrix((APVPAvals, (APVPArows, APVPAcols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5000x5000 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 11243494 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "APVPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5000x5000 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 5624247 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "APVPAhalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json.dump(aIndices, open('aIndices.json', 'w'))\n",
    "json.dump(authors, open('authors.json', 'w'))\n",
    "json.dump(pIndices, open('pIndices.json', 'w'))\n",
    "json.dump(papers, open('papers.json', 'w'))\n",
    "json.dump(tIndices, open('tIndices.json', 'w'))\n",
    "json.dump(terms, open('terms.json', 'w'))\n",
    "json.dump(vIndices, open('vIndices.json', 'w'))\n",
    "json.dump(venues, open('venues.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json.dump(A2P, open('A2P.json', 'w'))\n",
    "json.dump(P2A, open('P2A.json', 'w'))\n",
    "json.dump(P2V, open('P2V.json', 'w'))\n",
    "json.dump(V2P, open('V2P.json', 'w'))\n",
    "json.dump(P2T, open('P2T.json', 'w'))\n",
    "json.dump(T2P, open('T2P.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
